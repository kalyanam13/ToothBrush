{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804a6497-9432-4fcb-8c64-dfaa9e5f69be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Replace this with the path to your toothbrush dataset\n",
    "root_dir = r\"C:\\Users\\shubh\\Downloads\\ToothBrush\\toothbrush\\toothbrush\"  \n",
    "\n",
    "data = []\n",
    "\n",
    "# Process 'train' folder (only non-defective images available here)\n",
    "train_path = os.path.join(root_dir, 'train', 'good')\n",
    "if os.path.exists(train_path):\n",
    "    for img_name in os.listdir(train_path):\n",
    "        img_path = os.path.join(train_path, img_name)\n",
    "        data.append([img_path, 'train', 'non-defective', 'none'])\n",
    "\n",
    "# Process 'test' folder (contains both 'good' and 'defective')\n",
    "test_path = os.path.join(root_dir, 'test')\n",
    "for defect_type in ['good', 'defective']:\n",
    "    defect_path = os.path.join(test_path, defect_type)\n",
    "    if os.path.exists(defect_path):\n",
    "        label = 'non-defective' if defect_type == 'good' else 'defective'\n",
    "        defect_subtype = 'none' if label == 'non-defective' else 'unknown'  # No specific defect type in test\n",
    "        for img_name in os.listdir(defect_path):\n",
    "            img_path = os.path.join(defect_path, img_name)\n",
    "            data.append([img_path, 'test', label, defect_subtype])\n",
    "\n",
    "# Process 'ground_truth' folder (only defective images available here)\n",
    "ground_truth_path = os.path.join(root_dir, 'ground_truth')\n",
    "if os.path.exists(ground_truth_path):\n",
    "    for defect_type in os.listdir(ground_truth_path):\n",
    "        defect_path = os.path.join(ground_truth_path, defect_type)\n",
    "        for img_name in os.listdir(defect_path):\n",
    "            img_path = os.path.join(defect_path, img_name)\n",
    "            data.append([img_path, 'ground_truth', 'defective', defect_type])\n",
    "\n",
    "# Convert data into a DataFrame and save to CSV\n",
    "df = pd.DataFrame(data, columns=['image_path', 'dataset_type', 'label', 'defect_type'])\n",
    "df.to_csv('toothbrush_labels.csv', index=False)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9cd2f-3392-434c-af34-238fde13aff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86984bed-d315-49e1-9351-1a7cb9c7bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 validated image filenames belonging to 2 classes.\n",
      "Found 26 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "4/4 [==============================] - 35s 6s/step - loss: 0.8121 - accuracy: 0.4245 - val_loss: 0.8215 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7129 - accuracy: 0.6132 - val_loss: 0.9423 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7483 - accuracy: 0.5472 - val_loss: 0.6912 - val_accuracy: 0.6538\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.7035 - accuracy: 0.5377 - val_loss: 0.5124 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6685 - accuracy: 0.5755 - val_loss: 0.8259 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6587 - accuracy: 0.6132 - val_loss: 1.0172 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6440 - accuracy: 0.6415 - val_loss: 0.7325 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6540 - accuracy: 0.5755 - val_loss: 0.5109 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 15s 4s/step - loss: 0.6542 - accuracy: 0.6321 - val_loss: 0.5319 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 16s 4s/step - loss: 0.6105 - accuracy: 0.6604 - val_loss: 0.7391 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 4s 4s/step\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "non-defective       0.00      0.00      0.00         0\n",
      "    defective       1.00      0.08      0.14        26\n",
      "\n",
      "     accuracy                           0.08        26\n",
      "    macro avg       0.50      0.04      0.07        26\n",
      " weighted avg       1.00      0.08      0.14        26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\shubh\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\shubh\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Set paths\n",
    "root_dir = r\"C:\\Users\\shubh\\Downloads\\ToothBrush\\toothbrush\\toothbrush\"  # Update with your dataset path\n",
    "csv_file = \"toothbrush_labels.csv\"  # The CSV file created previously\n",
    "\n",
    "# Load the CSV with image paths and labels\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Set up data generators\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(128, 128),  # Adjust based on model input size\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    df,\n",
    "    x_col='image_path',\n",
    "    y_col='label',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    ResNet50(weights='imagenet', include_top=False, input_shape=(128, 128, 3)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "model.layers[0].trainable = False  # Freeze ResNet layers\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_images, val_labels = next(validation_generator)\n",
    "predictions = model.predict(val_images)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "print(classification_report(val_labels, predictions, target_names=['non-defective', 'defective']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b066c7c-59d7-4648-bd8b-78ec8da78dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "4/4 [==============================] - 6s 1s/step - loss: 0.9799 - accuracy: 0.5943 - val_loss: 0.5502 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "4/4 [==============================] - 4s 964ms/step - loss: 0.8696 - accuracy: 0.6226 - val_loss: 0.2980 - val_accuracy: 1.0000\n",
      "Epoch 3/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8165 - accuracy: 0.6509 - val_loss: 0.2586 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "4/4 [==============================] - 4s 977ms/step - loss: 0.8431 - accuracy: 0.6698 - val_loss: 0.3344 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "4/4 [==============================] - 4s 1s/step - loss: 0.8140 - accuracy: 0.7075 - val_loss: 0.3702 - val_accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "4/4 [==============================] - 4s 981ms/step - loss: 0.7929 - accuracy: 0.7075 - val_loss: 0.4094 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "4/4 [==============================] - 4s 989ms/step - loss: 0.7589 - accuracy: 0.7358 - val_loss: 0.3767 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "4/4 [==============================] - 4s 949ms/step - loss: 0.8318 - accuracy: 0.6792 - val_loss: 0.3115 - val_accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "4/4 [==============================] - 4s 945ms/step - loss: 0.7609 - accuracy: 0.7075 - val_loss: 0.3079 - val_accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "4/4 [==============================] - 4s 964ms/step - loss: 0.7730 - accuracy: 0.7170 - val_loss: 0.2955 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x246266dcfa0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = {0: 1., 1: 2.}  # Example: Increase weight of the minority class\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06fb2fe3-83ff-4467-b310-56cf1e6e2920",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a76808-8784-4e01-95cc-68d31e39c15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[0].layers:\n",
    "    layer.trainable = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39969fd4-97b6-4780-ac22-a6bb35200d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 187ms/step\n",
      "Confusion Matrix:\n",
      "[[26]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:409: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Get the true class labels from validation set\n",
    "val_images, val_labels = next(validation_generator)\n",
    "predictions = model.predict(val_images)\n",
    "predictions = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(val_labels, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37877a22-1954-4a5f-80b0-c0d458a366c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85d938a-bf0e-4a7c-907d-35b63493429c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(val_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc2f9ed-b5cc-4a9e-ba93-d9df18e86a3d",
   "metadata": {},
   "source": [
    "# Report: Toothbrush Defect Detection Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aaaeba-b232-4218-b277-3b104cebfabc",
   "metadata": {},
   "source": [
    "## Objective\n",
    "### The objective of this analysis is to develop a machine learning model that can classify toothbrush images into two categories: non-defective and defective. The model uses a ResNet50-based architecture with fine-tuning to detect defects in toothbrush images, leveraging image data from various folders."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac846b-cce0-47b5-abde-f4e0a6bff288",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "### 1. Dataset Overview:\n",
    "\n",
    "#### The dataset consists of images from three directories:\n",
    "#### Train: Contains only 'good' (non-defective) toothbrush images.\n",
    "#### Test: Contains both 'good' (non-defective) and 'defective' toothbrush images.\n",
    "#### Ground_truth: Contains only defective toothbrush images, used for model validation.\n",
    "#### The images were labeled as non-defective or defective based on their respective directories.\n",
    "### 2. Data Preprocessing:\n",
    "\n",
    "#### Image Augmentation: Applied to the images to increase the dataset's size and variability, which helps improve generalization:\n",
    "#### Horizontal flip\n",
    "#### Random rotations (up to 15 degrees)\n",
    "#### Rescaling: Pixel values of the images were rescaled to the range [0, 1] by dividing by 255.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f834177d-a592-446b-825e-a9c16fab84c0",
   "metadata": {},
   "source": [
    "### 3. Model Architecture:\n",
    "\n",
    "#### Base Model: Used the ResNet50 pre-trained on ImageNet as the backbone (without the top classification layer). This allows the model to leverage knowledge from a vast dataset, providing strong feature extraction capabilities.\n",
    "#### Added Layers:\n",
    "#### Flattened the output of ResNet50.\n",
    "#### Added a dense layer with 128 neurons and ReLU activation.\n",
    "#### Applied a Dropout layer (rate 0.5) to reduce overfitting.\n",
    "#### Final output layer: A single neuron with a sigmoid activation function to predict a binary outcome (non-defective vs defective).\n",
    "#### Training Configuration:\n",
    "#### Optimizer: Adam with a learning rate of 0.0001.\n",
    "#### Loss function: Binary cross-entropy, appropriate for binary classification tasks.\n",
    "#### Metrics: Accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0ae3b0-a1c3-469e-92bb-d40f306370f2",
   "metadata": {},
   "source": [
    "### 4. Model Training:\n",
    "\n",
    "#### The model was trained for 10 epochs using a batch size of 32. A validation split of 20% was used to evaluate the model during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcc584f-6f49-4a8b-8a0c-77b656e8e99e",
   "metadata": {},
   "source": [
    "## Results :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c35ba-733b-4f0b-859a-47f09b5a070f",
   "metadata": {},
   "source": [
    "### 1. Training and Validation Accuracy:\n",
    "\n",
    "#### The training process showed fluctuations in accuracy, with some improvement in later epochs, but it failed to generalize well to the validation set.\n",
    "#### The validation accuracy fluctuated significantly, reaching 100% accuracy for some epochs, but later falling to 0% in others. This indicates that the model may have overfitted on the training data or failed to generalize due to data issues.\n",
    "### 2. Classification Report: The classification report generated for the validation set showed:\n",
    "\n",
    "#### Precision: The model showed 100% precision for the \"defective\" class, meaning that when it predicted \"defective,\" it was always correct. However, it failed to predict any \"non-defective\" images.\n",
    "#### Recall: The recall for the \"defective\" class was very low (0.08), which suggests that the model had difficulty identifying all defective images. Recall for the \"non-defective\" class was 0% due to the absence of non-defective predictions.\n",
    "#### F1-Score: This was also very low, particularly for the non-defective class, indicating poor balance between precision and recall for this class.\n",
    "#### Accuracy: The overall accuracy of the model on the validation set was 8%, suggesting that the model's predictions were predominantly inaccurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e90dd9-d284-4dff-b64b-b2cdd41ecf41",
   "metadata": {},
   "source": [
    "### 3. Confusion Matrix: \n",
    "#### The confusion matrix output:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf086412-ca0a-466d-a06d-2c901d961087",
   "metadata": {},
   "source": [
    "[[26]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1d04b9-62dc-4914-8185-f6bd6054d133",
   "metadata": {},
   "source": [
    "#### Indicates that the model predicted all images as \"defective,\" with no \"non-defective\" predictions. This strongly suggests that the model is biased towards predicting the \"defective\" class, possibly due to an imbalance in the dataset or an issue with the model’s training procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac3a6ac-02c2-4561-9c45-573e7843df30",
   "metadata": {},
   "source": [
    "### 4. Predictions:\n",
    "\n",
    "#### The predictions showed a bias toward the \"defective\" class (all predictions were 1).\n",
    "#### The model’s failure to predict any \"non-defective\" images (all values in the predictions were 1) indicates that either the model has learned only to identify defective images or there is an issue with the label assignment or data representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa799d0d-274e-4314-b9db-9ebe18012258",
   "metadata": {},
   "source": [
    "## Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d98d5-2fb0-4f95-acdc-54e818d40e36",
   "metadata": {},
   "source": [
    "#### The model has shown limited success in predicting the \"defective\" class but is highly biased and does not predict the \"non-defective\" class. The next steps include addressing class imbalance, revisiting the model architecture, and evaluating the dataset's distribution to improve classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12986cb4-009a-4e98-adf7-7ea7e4c86105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
